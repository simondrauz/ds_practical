# Data Directory

Store nuScenes raw data, derived feature caches, and metadata exports here. Raw datasets should remain excluded from version control; rely on download scripts or external storage. A convenience `.gitignore` protects against accidentally committing heavy assets.

## Suggested Contents
- `raw/` pointers or symlinks to the official nuScenes release.
- `processed/` serialized feature tensors for Trajectron++.
- `metadata/` summaries describing manual and algorithmic cluster memberships.

## Acquisition Workflow
1. Create a nuScenes account at https://www.nuscenes.org/download and accept the license.
2. Download the **v1.0-mini** dataset and the **Map expansion pack (v1.3)**.
3. Extract both archives and organize under `raw/`:
   ```
   raw/
   ├── maps/
   │   ├── expansion/
   │   │   ├── boston-seaport.json
   │   │   ├── singapore-hollandvillage.json
   │   │   ├── singapore-onenorth.json
   │   │   └── singapore-queenstown.json
   │   └── (map image files)
   ├── samples/
   ├── sweeps/
   └── v1.0-mini/
   ```
4. Run `notebooks/00_setup_validation.ipynb` to verify the setup and trigger trajdata cache creation.
5. Populate `processed/` with reusable feature caches generated by scripts in `src/` (see forthcoming preprocessing utilities).

---

## Development Roadmap

**Current Status:** ✅ nuScenes v1.0-mini and map expansion acquired and validated

### Immediate Next Steps

1. **Data Characterization:**
   - Run exploratory analysis in `notebooks/01_data_characterization.ipynb` (to be created)
   - Document scene distribution across locations (Boston Seaport, Singapore districts)
   - Analyze agent type frequencies (vehicle, pedestrian, bicycle)
   - Profile trajectory characteristics (length, sampling rate, missing data patterns)

2. **Preprocessing Pipeline:**
   - Create `src/data/preprocessing.py` module for data cleaning
   - Implement trajectory filtering (min length, completeness criteria)
   - Generate derived features for clustering (curvature, speed statistics, etc.)
   - Save processed datasets to `processed/` directory

3. **Cluster Assignment:**
   - After clustering implementation (Step 2), save cluster labels to `metadata/`
   - Create lookup tables linking scene tokens to cluster IDs
   - Document cluster definitions in `metadata/cluster_definitions.json`

### Future Enhancements
- Expand to full nuScenes trainval split for final experiments
- Integrate additional sensor modalities (LIDAR, RADAR) if needed for analysis
- Create data versioning system for reproducibility

---

For more details on the overall project workflow, see the [main README](../README.md).

