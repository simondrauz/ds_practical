{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84fe0144",
   "metadata": {},
   "source": [
    "# Step 1 · nuScenes Data Characterization\n",
    "\n",
    "This notebook performs initial data setup and validation for the Trajectron++ federated learning research project. It loads the nuScenes dataset via TrajData and verifies that trajectory data and map resources are accessible.\n",
    "\n",
    "**Prerequisites:**\n",
    "- Python 3.10+ environment with dependencies from `requirements.txt` installed\n",
    "- nuScenes v1.0-mini dataset extracted to `data/raw/`\n",
    "- nuScenes map expansion pack (v1.3) extracted to `data/raw/maps/expansion/`\n",
    "- Kernel set to `.venv (Python 3.10.16)` or equivalent project environment\n",
    "\n",
    "**Expected Outcomes:**\n",
    "- Successful TrajData cache initialization\n",
    "- Dataset summary showing agent trajectory counts\n",
    "- Validation that map features are accessible for scene context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c86a875",
   "metadata": {},
   "source": [
    "## 1. Verify Data Directory\n",
    "\n",
    "Confirm that the nuScenes dataset is available at the expected location. This cell will raise an error if `data/raw/` is missing or incorrectly structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df96ca37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nuScenes root set to: /Users/simondrauz/Lokale Dokumente/Repositories/ds_practical/data/raw\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "NUSCENES_ROOT = Path('../data/raw').resolve()\n",
    "if not NUSCENES_ROOT.exists():\n",
    "    raise FileNotFoundError(f\"nuScenes root not found at {NUSCENES_ROOT}. Update the path before continuing.\")\n",
    "\n",
    "os.environ['NUSCENES_ROOT'] = str(NUSCENES_ROOT)\n",
    "print(f\"nuScenes root set to: {NUSCENES_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1ad373",
   "metadata": {},
   "source": [
    "## 2. Initialize TrajData Dataset\n",
    "\n",
    "Load the nuScenes mini split through TrajData's `UnifiedDataset` interface. On first execution, this will:\n",
    "- Build dataset caches (trajectory metadata, agent states)\n",
    "- Rasterize map data at 2 px/m resolution\n",
    "- Create vector map feature indices\n",
    "\n",
    "**Note:** Initial caching takes 3–5 minutes; subsequent runs are instant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bc70d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for matched scene tags: ['mini_train-nusc_mini-boston', 'mini_train-nusc_mini-singapore', 'nusc_mini-mini_val-boston', 'nusc_mini-mini_val-singapore']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting Scenes from nusc_mini: 100%|██████████| 4/4 [00:00<00:00, 1974.49it/s]\n",
      "\n",
      "Calculating Agent Data (Serially): 100%|██████████| 10/10 [00:00<00:00, 67979.00it/s]\n",
      "Calculating Agent Data (Serially): 100%|██████████| 10/10 [00:00<00:00, 67979.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 scenes in the scene index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Agent Data Index (Serially): 100%|██████████| 10/10 [00:00<00:00, 1853.26it/s]\n",
      "Creating Agent Data Index (Serially): 100%|██████████| 10/10 [00:00<00:00, 1853.26it/s]\n",
      "Structuring Agent Data Index: 100%|██████████| 10/10 [00:00<00:00, 21687.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded dataset with 26377 agent trajectories\n",
      "Dataset info: <trajdata.dataset.UnifiedDataset object at 0x333b80190>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from trajdata import UnifiedDataset\n",
    "\n",
    "try:\n",
    "    # Initialize TrajData with nuScenes mini split including map data\n",
    "    dataset = UnifiedDataset(\n",
    "        desired_data=[\"nusc_mini\"],  # Use 'nusc_trainval' for the full dataset\n",
    "        centric=\"agent\",\n",
    "        desired_dt=0.1,\n",
    "        history_sec=(3.2, 3.2),\n",
    "        future_sec=(4.8, 4.8),\n",
    "        incl_raster_map=True,  # Enable raster map rendering\n",
    "        raster_map_params={\n",
    "            \"px_per_m\": 2,  # 2 pixels per meter resolution\n",
    "            \"map_size_px\": 224,  # 224x224 pixel map patches\n",
    "        },\n",
    "        incl_vector_map=True,  # Enable vector map features\n",
    "        verbose=True,\n",
    "        data_dirs={\n",
    "            \"nusc_mini\": str(NUSCENES_ROOT)\n",
    "        },\n",
    "        num_workers=0,\n",
    "    )\n",
    "    print(f\"Successfully loaded dataset with {len(dataset)} agent trajectories\")\n",
    "    print(f\"Dataset info: {dataset}\")\n",
    "except FileNotFoundError as exc:\n",
    "    print(\"nuScenes data not found. Confirm the dataset is extracted under data/raw with proper folder structure.\")\n",
    "    raise\n",
    "except Exception as exc:\n",
    "    print(f\"Encountered an issue while initializing TrajData: {exc}\")\n",
    "    raise exc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552d1d59",
   "metadata": {},
   "source": [
    "## 3. Dataset Summary\n",
    "\n",
    "Inspect the loaded dataset to confirm accessibility and understand the data scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a273d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Display dataset statistics\n",
    "print(f\"Total agent trajectories: {len(dataset)}\")\n",
    "print(f\"Dataset description: {dataset}\")\n",
    "\n",
    "# Sample the first batch to verify data loading\n",
    "sample_batch = dataset[0]\n",
    "print(f\"\\nSample batch keys: {sample_batch.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556e932d",
   "metadata": {},
   "source": [
    "## Setup Complete ✓\n",
    "\n",
    "If the cells above executed without errors, your environment is ready for data characterization and clustering work. \n",
    "\n",
    "**Next Steps:**\n",
    "1. Commit the notebook and updated `requirements.txt` to the repository\n",
    "2. Share the repo URL with your colleague for collaborative setup\n",
    "3. Begin exploratory data analysis in subsequent notebook cells or a new notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
